import os
import csv
import time
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# ================= C·∫§U H√åNH =================
# Thay Telegram th√†nh Discord webhook
DISCORD_WEBHOOK_URL = "https://discord.com/api/webhooks/1380807005962371214/ZvDzloveJjS3syPVgMGvG_SpSeOeX2_NyV4XO4YJ4TXpt65XzxJJsFPYGwyEZu2Wd5Mc"  # Thay b·∫±ng webhook th·ª±c
BACKUP_SOURCE = "https://www.investing.com/economic-calendar/"  # Ngu·ªìn d·ª± ph√≤ng

# ================ TI·ªÜN √çCH ==================
def send_discord_alert(message):
    """G·ª≠i c·∫£nh b√°o qua Discord Webhook"""
    try:
        data = {
            "content": message
        }
        response = requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=10)
        if response.status_code != 204:
            print(f"‚ö†Ô∏è L·ªói g·ª≠i Discord: {response.status_code} {response.text}")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói g·ª≠i Discord: {e}")

def log_error(error_msg):
    """Ghi log l·ªói"""
    with open("scraper_errors.log", "a") as f:
        f.write(f"{datetime.now()}: {error_msg}\n")

# ============ CORE SCRAPING ================
class ForexFactoryScraper:
    def __init__(self):
        self.driver = self._init_driver()
        self.last_update = None

    def _init_driver(self):
        """Kh·ªüi t·∫°o tr√¨nh duy·ªát ·∫£o"""
        options = Options()
        options.add_argument("--headless=new")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-webgl")
        options.add_argument("--window-size=1920x1080")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        return webdriver.Chrome(options=options)

    def _scrape_events(self):
        """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ ForexFactory"""
        try:
            print("üåê ƒêang truy c·∫≠p ForexFactory...")
            self.driver.get("https://www.forexfactory.com/calendar")

            WebDriverWait(self.driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".calendar__row"))
            )
            time.sleep(3)  # ƒê·ª£i render JS

            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            events = []
            high_impact_count = 0

            for row in soup.select('.calendar__row:not(.calendar__row--header)'):
                try:
                    if not row.select_one('.calendar__time'):
                        continue

                    event_data = {
                        'Time': row.select_one('.calendar__time').get_text(strip=True) or "All Day",
                        'Currency': row.select_one('.calendar__currency').get_text(strip=True) if row.select_one('.calendar__currency') else "N/A",
                        'Event': row.select_one('.calendar__event').get_text(strip=True) if row.select_one('.calendar__event') else "N/A",
                        'Impact': row.select_one('.calendar__impact span')['title'] if row.select_one('.calendar__impact span') else "Unknown",
                        'Actual': row.select_one('.calendar__actual').get_text(strip=True) if row.select_one('.calendar__actual') else "N/A",
                        'Forecast': row.select_one('.calendar__forecast').get_text(strip=True) if row.select_one('.calendar__forecast') else "N/A",
                        'Previous': row.select_one('.calendar__previous').get_text(strip=True) if row.select_one('.calendar__previous') else "N/A"
                    }

                    if "High" in event_data['Impact']:
                        high_impact_count += 1
                        alert_msg = f"üö® **S·ª∞ KI·ªÜN QUAN TR·ªåNG**\n{event_data['Time']} {event_data['Currency']} - {event_data['Event']}"
                        send_discord_alert(alert_msg)

                    events.append(event_data)

                except Exception as e:
                    log_error(f"L·ªói x·ª≠ l√Ω d√≤ng: {str(e)}")
                    continue

            self.last_update = datetime.now().strftime("%Y-%m-%d %H:%M")
            return events, high_impact_count

        except Exception as e:
            log_error(f"L·ªói scrape ch√≠nh: {str(e)}")
            return None, 0

    def _save_to_csv(self, events):
        """L∆∞u d·ªØ li·ªáu v√†o CSV"""
        try:
            os.makedirs("data", exist_ok=True)
            filename = f"data/economic_calendar_{datetime.now().strftime('%Y%m%d')}.csv"

            with open(filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'Time', 'Currency', 'Event', 'Impact',
                    'Actual', 'Forecast', 'Previous'
                ])
                writer.writeheader()
                writer.writerows(events)

            return filename
        except Exception as e:
            log_error(f"L·ªói l∆∞u file: {str(e)}")
            return None

    def run(self):
        """Ch·∫°y quy tr√¨nh ch√≠nh"""
        try:

            print("üîÑ B·∫Øt ƒë·∫ßu c·∫≠p nh·∫≠t d·ªØ li·ªáu...")
            events, hi_count = self._scrape_events()

            if not events:
                print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu, th·ª≠ ngu·ªìn d·ª± ph√≤ng...")
                return False

            saved_file = self._save_to_csv(events)
            if saved_file:
                summary = (
                    f"üìä **C·∫¨P NH·∫¨T TH√ÄNH C√îNG**\n"
                    f"‚Ä¢ S·ª± ki·ªán: {len(events)}\n"
                    f"‚Ä¢ High Impact: {hi_count}\n"
                    f"‚Ä¢ File: {saved_file}"
                )
                send_discord_alert(summary)
                print(f"‚úÖ ƒê√£ l∆∞u {len(events)} s·ª± ki·ªán ({hi_count} High Impact)")
                return True

            return False

        except Exception as e:
            log_error(f"L·ªói h·ªá th·ªëng: {str(e)}")
            return False

    def __del__(self):
        """D·ªçn d·∫πp khi ƒë√≥ng"""
        if hasattr(self, 'driver'):
            self.driver.quit()

# =============== MAIN ================
if __name__ == "__main__":
    scraper = ForexFactoryScraper()

    if scraper.run():
        print("üéØ Ho√†n t·∫•t!")
    else:
        print("üí• C√≥ l·ªói x·∫£y ra!")
        send_discord_alert("‚ö†Ô∏è **L·ªñI H·ªÜ TH·ªêNG**\nScraper g·∫∑p s·ª± c·ªë nghi√™m tr·ªçng!")

    input("Nh·∫•n Enter ƒë·ªÉ ƒë√≥ng...")
